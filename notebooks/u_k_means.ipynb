{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised k-means Clustering Algorithm \n",
    "\n",
    "**References**\n",
    "- [Paper | Unsupervised K-Means Clustering Algorithm](https://ieeexplore.ieee.org/document/9072123)\n",
    "- [GitHub u-k-means python code](https://github.com/scikit-learn/scikit-learn/issues/23967)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating custom class for u_k_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class u_k_means():\n",
    "    def __init__(self, thres, beta, gamma, rate, t_max):\n",
    "        self.thres = thres\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.rate = rate\n",
    "        self.t_max = t_max\n",
    "\n",
    "    def fit(self, points, y):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        # initializations\n",
    "        cluster_n = points.shape[0]\n",
    "        clust_cen = points + 0.0001\n",
    "        alpha = np.ones((1, cluster_n)) * 1 / cluster_n\n",
    "        err = 10\n",
    "\n",
    "        c_history = []\n",
    "\n",
    "        while cluster_n > 1 and err >= self.thres:\n",
    "            self.rate = self.rate + 1\n",
    "\n",
    "            # Step 2: Compute membership\n",
    "            u = np.zeros((points.shape[0], cluster_n))\n",
    "            D7 = np.zeros((points.shape[0],0))\n",
    "            for k in range(cluster_n):\n",
    "                D1 = np.subtract(points, clust_cen[k, :])\n",
    "                D2 = np.power(D1, 2)\n",
    "                D3 = np.sum(D2, 1)\n",
    "                D4 = D3\n",
    "                D5 = self.gamma * math.log(alpha[0, k])\n",
    "                D6 = np.subtract(D4, D5)\n",
    "                D7 = np.concatenate((D7, D6[:, np.newaxis]),axis=1)\n",
    "\n",
    "            if self.rate == 1:\n",
    "                D8 = D7\n",
    "                np.fill_diagonal(D7, np.nan)\n",
    "                val = np.min(D7, axis=1)\n",
    "                idx = np.argmax(D7, axis=1)\n",
    "                np.fill_diagonal(D7, np.diag(D8))\n",
    "            else:\n",
    "                val = np.min(D7, axis=1)\n",
    "                idx = np.argmax(D7, axis=1)\n",
    "\n",
    "            for i in range(points.shape[0]):\n",
    "                u[i, idx[i]] = 1\n",
    "            \n",
    "            print(u)\n",
    "            # Step 3: Compute gamma\n",
    "            gamma = math.exp(-cluster_n / 450)\n",
    "\n",
    "            # Step 4: Update alpha\n",
    "            new_alpha = np.zeros((1, cluster_n))\n",
    "            for k in range(cluster_n):\n",
    "                temp1 = np.power(u[:, k], self.beta)\n",
    "                temp2 = np.sum(temp1)\n",
    "                temp3 = temp2 / points.shape[0]\n",
    "                new_alpha[0, k] = temp3\n",
    "            \n",
    "            # Step 5: Update beta\n",
    "            eta = 1 / points.shape[0]\n",
    "            temp9 = 0\n",
    "            for k in range(cluster_n):\n",
    "                temp8 = math.exp(-eta * points.shape[0] * abs(new_alpha[0, k] - alpha[0, k]))\n",
    "                temp9 = temp9 + temp8\n",
    "            temp9 = temp9 / cluster_n\n",
    "            temp10 = 1 - max(np.sum(u, 1) / points.shape[0])\n",
    "            temp11 = sum(alpha[0, :] * np.log(alpha[0, :]))\n",
    "            temp12 = temp10 / (-max(alpha[0, :]) * temp11)\n",
    "            \n",
    "            new_beta = min(temp9, temp12)\n",
    "            \n",
    "            # Step 6: Update number of clusters\n",
    "            index = np.where(new_alpha <= 1 / points.shape[0])\n",
    "            \n",
    "            # ADJUST ALPHA\n",
    "            adj_alpha = new_alpha\n",
    "            adj_alpha = np.delete(adj_alpha, index)\n",
    "            adj_alpha = adj_alpha / sum(adj_alpha)\n",
    "            new_alpha = adj_alpha\n",
    "            if new_alpha.shape[0] == 1:\n",
    "                new_alpha = alpha\n",
    "                break\n",
    "            \n",
    "            # Update NUMBER OF CLUSTER\n",
    "            new_cluster_n = new_alpha.shape[0]\n",
    "            \n",
    "            # ADJUST MEMBERSHIP(U)\n",
    "            adj_u = u\n",
    "            adj_u = np.delete(adj_u, index, 1)\n",
    "            adj_u = adj_u / np.sum(adj_u, 1)[:, None]\n",
    "            adj_u[np.isnan(adj_u)] = 0\n",
    "            new_u = adj_u\n",
    "            \n",
    "            if self.rate >= 60 and new_cluster_n - cluster_n == 0:\n",
    "                new_beta = 0\n",
    "                \n",
    "            # Update Cluster Centers\n",
    "            new_clust_cen = []\n",
    "            for k in range(new_cluster_n):\n",
    "                temp4 = np.zeros((1, points.shape[1]))\n",
    "                temp5 = 0\n",
    "                for i in range(points.shape[0]):\n",
    "                    temp4 = temp4 + new_u[i, k] * points[i, :]\n",
    "                    temp5 = temp5 + new_u[i, k]\n",
    "                new_clust_cen.append(temp4 / temp5)\n",
    "                # np.concatenate((new_clust_cen, temp4 / temp5), axis=0)\n",
    "            new_clust_cen = np.array(new_clust_cen)\n",
    "            print(new_clust_cen) \n",
    "            print(new_clust_cen.shape)    \n",
    "            new_clust_cen[np.isnan(new_clust_cen)] = sum(np.mean(points))\n",
    "            \n",
    "            # STEP 8: Convergence criteria\n",
    "            error = []\n",
    "            for k in range(new_cluster_n):\n",
    "                error = np.concatenate((error, np.linalg.norm(new_clust_cen[k, :] - clust_cen[k, :])))\n",
    "                \n",
    "            err = max(error)\n",
    "            \n",
    "            clust_cen = new_clust_cen\n",
    "            cluster_n = new_cluster_n\n",
    "            alpha = new_alpha\n",
    "            beta = new_beta\n",
    "            u = new_u\n",
    "            c_history.append(cluster_n)\n",
    "            c_history = np.array(c_history)\n",
    "            # c_history = np.concatenate((c_history, cluster_n))\n",
    "            \n",
    "        # Step 9: Cluster labeling\n",
    "        clust = []\n",
    "        for i in range(points.shape[0]):\n",
    "            clust.append(val[i])\n",
    "            # np.concatenate((clust, idx[i]))\n",
    "            \n",
    "        return clust, c_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing u-k-means with iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input data\n",
    "points = iris.data\n",
    "y = iris.target\n",
    "label = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "thres = 0.1\n",
    "beta = 1\n",
    "gamma = 1\n",
    "rate = 0\n",
    "t_max = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 109\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# error = np.concatenate((error, np.linalg.norm(new_clust_cen[k, :] - clust_cen[k, :])))\u001b[39;00m\n\u001b[1;32m    107\u001b[0m error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(error)\n\u001b[0;32m--> 109\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m clust_cen \u001b[38;5;241m=\u001b[39m new_clust_cen\n\u001b[1;32m    112\u001b[0m cluster_n \u001b[38;5;241m=\u001b[39m new_cluster_n\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# initializations\n",
    "cluster_n = points.shape[0]\n",
    "clust_cen = points + 0.0001\n",
    "alpha = np.ones((1, cluster_n)) * 1 / cluster_n\n",
    "err = 10\n",
    "\n",
    "t_max = 100\n",
    "\n",
    "c_history = []\n",
    "\n",
    "while cluster_n > 1 and err >= thres:\n",
    "    rate = rate + 1\n",
    "\n",
    "    # Step 2: Compute membership\n",
    "    u = np.zeros((points.shape[0], cluster_n))\n",
    "    D7 = []\n",
    "    for k in range(cluster_n):\n",
    "        D1 = np.subtract(points, clust_cen[k, :])\n",
    "        D2 = np.power(D1, 2)\n",
    "        D3 = np.sum(D2, 1)\n",
    "        D4 = D3\n",
    "        D5 = gamma * math.log(alpha[0, k])\n",
    "        D6 = np.subtract(D4, D5)\n",
    "        D7.append(D6)\n",
    "    D7 = np.array(D7)\n",
    "\n",
    "    if rate == 1:\n",
    "        D8 = D7\n",
    "        np.fill_diagonal(D7, np.nan)\n",
    "        val = np.nanmin(D7, axis=1)\n",
    "        idx = np.argmin(D7, axis=1)\n",
    "        np.fill_diagonal(D7, np.diag(D8))\n",
    "    else:\n",
    "        val = np.min(D7, axis=1)\n",
    "        idx = np.argmin(D7, axis=1)\n",
    "\n",
    "    for i in range(points.shape[0]):\n",
    "        u[i, idx[i]] = 1\n",
    "\n",
    "    # Step 3: Compute gamma\n",
    "    gamma = math.exp(-cluster_n / 450)\n",
    "\n",
    "    # Step 4: Update alpha\n",
    "    new_alpha = np.zeros((1, cluster_n))\n",
    "    for k in range(cluster_n):\n",
    "        temp1 = np.power(u[:, k], beta)\n",
    "        temp2 = np.sum(temp1)\n",
    "        temp3 = temp2 / points.shape[0]\n",
    "        new_alpha[0, k] = temp3\n",
    "\n",
    "    # Step 5: Update beta\n",
    "    eta = 1 / points.shape[0]\n",
    "    temp9 = 0\n",
    "    for k in range(cluster_n):\n",
    "        temp8 = math.exp(-eta * points.shape[0] * abs(new_alpha[0, k] - alpha[0, k]))\n",
    "        temp9 = temp9 + temp8\n",
    "    temp9 = temp9 / cluster_n\n",
    "    temp10 = 1 - max(np.sum(u, 1) / points.shape[0])\n",
    "    temp11 = sum(alpha[0, :] * np.log(alpha[0, :]))\n",
    "    temp12 = temp10 / (-max(alpha[0, :]) * temp11)\n",
    "\n",
    "    new_beta = min(temp9, temp12)\n",
    "\n",
    "    # Step 6: Update number of clusters\n",
    "    index = np.where(new_alpha <= 1 / points.shape[0])\n",
    "\n",
    "    # ADJUST ALPHA\n",
    "    adj_alpha = new_alpha\n",
    "    adj_alpha = np.delete(adj_alpha, index)\n",
    "    adj_alpha = adj_alpha / sum(adj_alpha)\n",
    "    new_alpha = adj_alpha\n",
    "    if new_alpha.shape[0] == 1:\n",
    "        new_alpha = alpha\n",
    "        # break\n",
    "\n",
    "    # Update NUMBER OF CLUSTER\n",
    "    new_cluster_n = new_alpha.shape[0]\n",
    "\n",
    "    # ADJUST MEMBERSHIP(U)\n",
    "    adj_u = u\n",
    "    adj_u = np.delete(adj_u, index, 1)\n",
    "    adj_u = adj_u / np.sum(adj_u, 1)[:, None]\n",
    "    adj_u[np.isnan(adj_u)] = 0\n",
    "    new_u = adj_u\n",
    "\n",
    "    if rate >= 60 and new_cluster_n - cluster_n == 0:\n",
    "        new_beta = 0\n",
    "\n",
    "    # Update Cluster Centers\n",
    "    new_clust_cen = []\n",
    "    for k in range(new_cluster_n):\n",
    "        temp4 = np.zeros((1, points.shape[1]))\n",
    "        temp5 = 0\n",
    "        for i in range(points.shape[0]):\n",
    "            temp4 = temp4 + new_u[i, k] * points[i, :]\n",
    "            temp5 = temp5 + new_u[i, k]\n",
    "        new_clust_cen.append(temp4 / temp5)\n",
    "        # new_clust_cen = np.concatenate((new_clust_cen, temp4 / temp5), axis=0)\n",
    "    new_clust_cen = np.array(new_clust_cen)\n",
    "    new_clust_cen[np.isnan(new_clust_cen)] = sum(np.mean(points,axis=0))\n",
    "\n",
    "    # STEP 8: Convergence criteria\n",
    "    error = []\n",
    "    for k in range(new_cluster_n):\n",
    "        error.append(np.linalg.norm(new_clust_cen[k, :] - clust_cen[k, :]))\n",
    "        # error = np.concatenate((error, np.linalg.norm(new_clust_cen[k, :] - clust_cen[k, :])))\n",
    "    error = np.array(error)\n",
    "\n",
    "    err = max(error)\n",
    "\n",
    "    clust_cen = new_clust_cen\n",
    "    cluster_n = new_cluster_n\n",
    "    alpha = new_alpha\n",
    "    beta = new_beta\n",
    "    u = new_u\n",
    "    c_history.append(c_history)\n",
    "    # c_history = np.array(c_history)\n",
    "    # c_history = np.concatenate((c_history, cluster_n))\n",
    "\n",
    "# Step 9: Cluster labeling\n",
    "clust = []\n",
    "for i in range(points.shape[0]):\n",
    "    clust.append(val[i])\n",
    "    # clust = np.concatenate((clust, idx[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7165313105737893"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743,\n",
       " 3.5902771140860743]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[[6.65964912 3.07368421 5.30526316 1.8754386 ]]\n",
      "\n",
      " [[5.95416667 2.66666667 4.83333333 1.6       ]]\n",
      "\n",
      " [[5.43       2.36       3.75       1.1       ]]\n",
      "\n",
      " [[5.08275862 3.33275862 1.78103448 0.37758621]]]\n",
      "(4, 1, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/mj9t8ccd7bn74b0c25x8xjth0000gn/T/ipykernel_45969/2820772806.py:92: RuntimeWarning: invalid value encountered in divide\n",
      "  adj_u = adj_u / np.sum(adj_u, 1)[:, None]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[260], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m clf \u001b[38;5;241m=\u001b[39m u_k_means(\n\u001b[1;32m      2\u001b[0m     thres\u001b[38;5;241m=\u001b[39mthres,\n\u001b[1;32m      3\u001b[0m     beta\u001b[38;5;241m=\u001b[39mbeta,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     t_max\u001b[38;5;241m=\u001b[39mt_max\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m clusters, cluster_history \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[249], line 112\u001b[0m, in \u001b[0;36mu_k_means.fit\u001b[0;34m(self, points, y)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_clust_cen) \n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_clust_cen\u001b[38;5;241m.\u001b[39mshape)    \n\u001b[0;32m--> 112\u001b[0m new_clust_cen[np\u001b[38;5;241m.\u001b[39misnan(new_clust_cen)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(points))\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# STEP 8: Convergence criteria\u001b[39;00m\n\u001b[1;32m    115\u001b[0m error \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "clf = u_k_means(\n",
    "    thres=thres,\n",
    "    beta=beta,\n",
    "    gamma=gamma,\n",
    "    rate=rate,\n",
    "    t_max=t_max\n",
    ")\n",
    "\n",
    "clusters, cluster_history = clf.fit(points=points, y=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
