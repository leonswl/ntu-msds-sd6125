{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised k-means Clustering Algorithm \n",
    "\n",
    "**References**\n",
    "- [Paper | Unsupervised K-Means Clustering Algorithm](https://ieeexplore.ieee.org/document/9072123)\n",
    "- [GitHub u-k-means python code](https://github.com/scikit-learn/scikit-learn/issues/23967)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating custom class for u_k_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing u-k-means with iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input data\n",
    "points = iris.data\n",
    "y = iris.target\n",
    "label = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "thres = 0.1\n",
    "beta = 1\n",
    "gamma = 1\n",
    "rate = 0\n",
    "t_max = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializations\n",
    "cluster_n = points.shape[0]\n",
    "clust_cen = points + 0.0001\n",
    "alpha = np.ones((1, cluster_n)) * 1 / cluster_n\n",
    "err = 10\n",
    "t_max = 100\n",
    "\n",
    "c_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 102\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# error = np.concatenate((error, np.linalg.norm(new_clust_cen[k, :] - clust_cen[k, :])))\u001b[39;00m\n\u001b[1;32m    100\u001b[0m error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(error)\n\u001b[0;32m--> 102\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m clust_cen \u001b[38;5;241m=\u001b[39m new_clust_cen\n\u001b[1;32m    105\u001b[0m cluster_n \u001b[38;5;241m=\u001b[39m new_cluster_n\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "while cluster_n > 1 and err >= thres:\n",
    "    print(counter)\n",
    "    rate = rate + 1\n",
    "\n",
    "    # Step 2: Compute membership\n",
    "    u = np.zeros((points.shape[0], cluster_n))\n",
    "    D7 = []\n",
    "    for k in range(cluster_n):\n",
    "        D1 = np.subtract(points, clust_cen[k, :])\n",
    "        D2 = np.power(D1, 2)\n",
    "        D3 = np.sum(D2, 1)\n",
    "        D4 = D3\n",
    "        D5 = gamma * math.log(alpha[0, k])\n",
    "        D6 = np.subtract(D4, D5)\n",
    "        D7.append(D6)\n",
    "    D7 = np.array(D7)\n",
    "\n",
    "    if rate == 1:\n",
    "        D8 = D7\n",
    "        np.fill_diagonal(D7, np.nan)\n",
    "        val = np.nanmin(D7, axis=1)\n",
    "        idx = np.argmin(D7, axis=1)\n",
    "        np.fill_diagonal(D7, np.diag(D8))\n",
    "    else:\n",
    "        val = np.min(D7, axis=1)\n",
    "        idx = np.argmin(D7, axis=1)\n",
    "\n",
    "    for i in range(points.shape[0]):\n",
    "        u[i, idx[i]] = 1\n",
    "\n",
    "    # Step 3: Compute gamma\n",
    "    gamma = math.exp(-cluster_n / 450)\n",
    "\n",
    "    # Step 4: Update alpha\n",
    "    new_alpha = np.zeros((1, cluster_n))\n",
    "    for k in range(cluster_n):\n",
    "        temp1 = np.power(u[:, k], beta)\n",
    "        temp2 = np.sum(temp1)\n",
    "        temp3 = temp2 / points.shape[0]\n",
    "        new_alpha[0, k] = temp3\n",
    "\n",
    "    # Step 5: Update beta\n",
    "    eta = 1 / points.shape[0]\n",
    "    temp9 = 0\n",
    "    for k in range(cluster_n):\n",
    "        temp8 = math.exp(-eta * points.shape[0] * abs(new_alpha[0, k] - alpha[0, k]))\n",
    "        temp9 = temp9 + temp8\n",
    "    temp9 = temp9 / cluster_n\n",
    "    temp10 = 1 - max(np.sum(u, 1) / points.shape[0])\n",
    "    temp11 = sum(alpha[0, :] * np.log(alpha[0, :]))\n",
    "    temp12 = temp10 / (-max(alpha[0, :]) * temp11)\n",
    "\n",
    "    new_beta = min(temp9, temp12)\n",
    "\n",
    "    # Step 6: Update number of clusters\n",
    "    index = np.where(new_alpha <= 1 / points.shape[0])\n",
    "\n",
    "    # ADJUST ALPHA\n",
    "    adj_alpha = new_alpha\n",
    "    adj_alpha = np.delete(adj_alpha, index)\n",
    "    adj_alpha = adj_alpha / sum(adj_alpha)\n",
    "    new_alpha = adj_alpha\n",
    "    if new_alpha.shape[0] == 1:\n",
    "        new_alpha = alpha\n",
    "        # break\n",
    "\n",
    "    # Update NUMBER OF CLUSTER\n",
    "    new_cluster_n = new_alpha.shape[0]\n",
    "\n",
    "    # ADJUST MEMBERSHIP(U)\n",
    "    adj_u = u\n",
    "    adj_u = np.delete(adj_u, index, 1)\n",
    "    adj_u = adj_u / np.sum(adj_u, 1)[:, None]\n",
    "    adj_u[np.isnan(adj_u)] = 0\n",
    "    new_u = adj_u\n",
    "\n",
    "    if rate >= 60 and new_cluster_n - cluster_n == 0:\n",
    "        new_beta = 0\n",
    "\n",
    "    # Update Cluster Centers\n",
    "    new_clust_cen = []\n",
    "    for k in range(new_cluster_n):\n",
    "        temp4 = np.zeros((1, points.shape[1]))\n",
    "        temp5 = 0\n",
    "        for i in range(points.shape[0]):\n",
    "            temp4 = temp4 + new_u[i, k] * points[i, :]\n",
    "            temp5 = temp5 + new_u[i, k]\n",
    "        new_clust_cen.append(temp4 / temp5)\n",
    "        # new_clust_cen = np.concatenate((new_clust_cen, temp4 / temp5), axis=0)\n",
    "    new_clust_cen = np.array(new_clust_cen)\n",
    "    new_clust_cen[np.isnan(new_clust_cen)] = sum(np.mean(points,axis=0))\n",
    "\n",
    "    # STEP 8: Convergence criteria\n",
    "    error = []\n",
    "    for k in range(new_cluster_n):\n",
    "        error.append(np.linalg.norm(new_clust_cen[k, :] - clust_cen[k, :]))\n",
    "        # error = np.concatenate((error, np.linalg.norm(new_clust_cen[k, :] - clust_cen[k, :])))\n",
    "    error = np.array(error)\n",
    "\n",
    "    err = max(error)\n",
    "\n",
    "    clust_cen = new_clust_cen\n",
    "    cluster_n = new_cluster_n\n",
    "    alpha = new_alpha\n",
    "    beta = new_beta\n",
    "    u = new_u\n",
    "    c_history.append(c_history)\n",
    "    # c_history = np.array(c_history)\n",
    "    # c_history = np.concatenate((c_history, cluster_n))\n",
    "\n",
    "# Step 9: Cluster labeling\n",
    "clust = []\n",
    "for i in range(points.shape[0]):\n",
    "    clust.append(val[i])\n",
    "    # clust = np.concatenate((clust, idx[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn import datasets\n",
    "\n",
    "# load dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# define input data\n",
    "points = iris.data\n",
    "y = iris.target\n",
    "label = y\n",
    "\n",
    "# define parameters\n",
    "thres = 0.1\n",
    "beta = 1\n",
    "gamma = 1\n",
    "rate = 0\n",
    "\n",
    "# initializations\n",
    "cluster_n = points.shape[0]\n",
    "clust_cen = points + 0.0001\n",
    "alpha = np.ones((1, cluster_n)) * 1 / cluster_n\n",
    "err = 10\n",
    "\n",
    "t_max = 100\n",
    "\n",
    "c_history = []\n",
    "\n",
    "while cluster_n > 1 and err >= thres:\n",
    "    rate = rate + 1\n",
    "\n",
    "    # Step 2: Compute membership\n",
    "    u = np.zeros((points.shape[0], cluster_n))\n",
    "    D7 = np.zeros((points.shape[0], cluster_n))  # Initialize D7 properly\n",
    "    for k in range(cluster_n):\n",
    "        D1 = np.subtract(points, clust_cen[k, :])\n",
    "        D2 = np.power(D1, 2)\n",
    "        D3 = np.sum(D2, 1)\n",
    "        D4 = D3\n",
    "        D5 = gamma * math.log(alpha[0, k])\n",
    "        D6 = np.subtract(D4, D5)\n",
    "        D7[:, k] = D6\n",
    "\n",
    "    if rate == 1:\n",
    "        D8 = D7\n",
    "        np.fill_diagonal(D7, np.nan)\n",
    "        idx = np.nanmin(D7, axis=1).astype(int)\n",
    "        np.fill_diagonal(D7, np.diag(D8))\n",
    "    else:\n",
    "        idx = np.min(D7, axis=1).astype(int)\n",
    "\n",
    "    for i in range(points.shape[0]):\n",
    "        u[i, idx[i]] = 1\n",
    "\n",
    "    # Step 3: Compute gamma\n",
    "    gamma = math.exp(-cluster_n / 450)\n",
    "\n",
    "    # Step 4: Update alpha\n",
    "    new_alpha = np.zeros((1, cluster_n))\n",
    "    for k in range(cluster_n):\n",
    "        temp1 = np.power(u[:, k], beta)\n",
    "        temp2 = np.sum(temp1)\n",
    "        temp3 = temp2 / points.shape[0]\n",
    "        new_alpha[0, k] = temp3\n",
    "\n",
    "    # Step 5: Update beta\n",
    "    eta = 1 / points.shape[0]\n",
    "    temp9 = 0\n",
    "    for k in range(cluster_n):\n",
    "        temp8 = math.exp(-eta * points.shape[0] * abs(new_alpha[0, k] - alpha[0, k]))\n",
    "        temp9 = temp9 + temp8\n",
    "    temp9 = temp9 / cluster_n\n",
    "    temp10 = 1 - max(np.sum(u, 1) / points.shape[0])\n",
    "    temp11 = sum(alpha[0, :] * np.log(alpha[0, :]))\n",
    "    temp12 = temp10 / (-max(alpha[0, :]) * temp11)\n",
    "\n",
    "    new_beta = min(temp9, temp12)\n",
    "\n",
    "    # Step 6: Update number of clusters\n",
    "    index = np.where(new_alpha <= 1 / points.shape[0])\n",
    "\n",
    "    # ADJUST ALPHA\n",
    "    adj_alpha = new_alpha\n",
    "    adj_alpha = np.delete(adj_alpha, index)\n",
    "    adj_alpha = adj_alpha / sum(adj_alpha)\n",
    "    new_alpha = adj_alpha\n",
    "    if len(new_alpha.shape) > 1 and new_alpha.shape[1] == 1:\n",
    "        new_alpha = alpha\n",
    "        break\n",
    "\n",
    "    # Update NUMBER OF CLUSTER\n",
    "    if len(new_alpha.shape) > 1:\n",
    "        new_cluster_n = new_alpha.shape[1]\n",
    "\n",
    "    # ADJUST MEMBERSHIP(U)\n",
    "    adj_u = u\n",
    "    adj_u = np.delete(adj_u, index, 1)\n",
    "    adj_u = adj_u / np.sum(adj_u, 1)[:, None]\n",
    "    adj_u[np.isnan(adj_u)] = 0\n",
    "    new_u = adj_u\n",
    "\n",
    "    if rate >= 60 and new_cluster_n - cluster_n == 0:\n",
    "        new_beta = 0\n",
    "\n",
    "    # Update Cluster Centers\n",
    "    new_clust_cen = []\n",
    "    for k in range(new_cluster_n):\n",
    "        temp4 = np.zeros((1, points.shape[1]))\n",
    "        temp5 = 0\n",
    "        for i in range(points.shape[0]):\n",
    "            temp4 = temp4 + new_u[i, k] * points[i, :]\n",
    "            temp5 = temp5 + new_u[i, k]\n",
    "        new_clust_cen.append(temp4 / temp5)\n",
    "\n",
    "    new_clust_cen = np.array(new_clust_cen)\n",
    "    new_clust_cen[np.isnan(new_clust_cen)] = np.mean(points)\n",
    "\n",
    "    # STEP 8: Convergence criteria\n",
    "    error = []\n",
    "    for k in range(new_cluster_n):\n",
    "        error.append(np.linalg.norm(new_clust_cen[k, :] - clust_cen[k, :]))\n",
    "\n",
    "    err = max(error)\n",
    "\n",
    "    clust_cen = new_clust_cen\n",
    "    cluster_n = new_cluster_n\n",
    "    alpha = new_alpha\n",
    "    beta = new_beta\n",
    "    u = new_u\n",
    "    c_history = np.concatenate((c_history, [cluster_n]))\n",
    "\n",
    "# Step 9: Cluster labeling\n",
    "clust = np.array([])\n",
    "for i in range(points.shape[0]):\n",
    "    clust = np.concatenate((clust, [int(idx[i])]))  # Cast idx to int\n",
    "\n",
    "print(clust)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = u_k_means(\n",
    "#     thres=thres,\n",
    "#     beta=beta,\n",
    "#     gamma=gamma,\n",
    "#     rate=rate,\n",
    "#     t_max=t_max\n",
    "# )\n",
    "\n",
    "# clusters, cluster_history = clf.fit(points=points, y=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
